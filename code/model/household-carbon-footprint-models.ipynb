{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\vince\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
<<<<<<< HEAD
      "Requirement already satisfied: ipynb in c:\\users\\miche\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: mlxtend in c:\\users\\miche\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.5)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from mlxtend) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->mlxtend) (1.15.0)\n"
=======
      "Collecting ipynb\n",
      "  Downloading ipynb-0.5.1-py3-none-any.whl (6.9 kB)\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (general_model_pipeline_vl.ipynb, line 35)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/Henry/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-943a4e100e3e>\"\u001b[0m, line \u001b[1;32m5\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import ipynb.fs.full.general_model_pipeline_vl as gmp\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m971\u001b[0m, in \u001b[1;35m_find_and_load\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m955\u001b[0m, in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m665\u001b[0m, in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m674\u001b[0m, in \u001b[1;35mexec_module\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/Henry/miniconda3/lib/python3.6/site-packages/ipynb/fs/full/__init__.py\"\u001b[0;36m, line \u001b[0;32m43\u001b[0;36m, in \u001b[0;35mget_code\u001b[0;36m\u001b[0m\n\u001b[0;31m    return self.source_to_code(code_from_ipynb(nb), self.path)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/Henry/Sites/carbon-footprint/code/model/general_model_pipeline_vl.ipynb\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    \"\\n\",\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
>>>>>>> 925543da5d490ccd4c20cf6f298124ea0dacefd7
=======
      "Requirement already satisfied: ipynb in c:\\users\\vince\\anaconda3\\lib\\site-packages (0.5.1)\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "# linear modelling functions\n",
    "#HENRY AND JUN\n",
    "#MERGED KAMMEN + COOLCLIMAE\n",
    "# vincent\n",
    "!pip install ipynb\n",
    "!pip install mlxtend\n",
    "import ipynb.fs.full.general_model_pipeline_vl as gmp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset \n",
    "\n",
    "These models will use 80% training data and 20% of testing data."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": null,
>>>>>>> 925543da5d490ccd4c20cf6f298124ea0dacefd7
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 100\n",
    "np.random.seed(100)\n",
    "\n",
    "# frac train\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< HEAD
=======
>>>>>>> Stashed changes
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_income</th>\n",
       "      <th>input_footprint_transportation_num_vehicles</th>\n",
       "      <th>input_footprint_transportation_mpg1</th>\n",
       "      <th>input_footprint_transportation_miles1</th>\n",
       "      <th>input_footprint_transportation_fuel1</th>\n",
       "      <th>airflights</th>\n",
       "      <th>input_footprint_housing_electricity_dollars</th>\n",
       "      <th>input_footprint_housing_squarefeet</th>\n",
       "      <th>input_footprint_shopping_goods_clothing</th>\n",
       "      <th>result_grand_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1590.5</td>\n",
       "      <td>136.451019</td>\n",
       "      <td>23.324704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>251.748512</td>\n",
       "      <td>37.518058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>198.743174</td>\n",
       "      <td>29.656163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>81.291788</td>\n",
       "      <td>17.516040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>307.046647</td>\n",
       "      <td>37.328012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>349.025009</td>\n",
       "      <td>45.620547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>92.352685</td>\n",
       "      <td>12.257499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>76.754155</td>\n",
       "      <td>17.213900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>293.132048</td>\n",
       "      <td>36.638812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>438.915916</td>\n",
       "      <td>55.037524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      input_income  input_footprint_transportation_num_vehicles  \\\n",
       "588            5.0                                          1.0   \n",
       "983            9.0                                          2.0   \n",
       "638            6.0                                          2.0   \n",
       "266            3.0                                          1.0   \n",
       "1010          10.0                                          2.0   \n",
       "...            ...                                          ...   \n",
       "1025          10.0                                          2.0   \n",
       "141            2.0                                          1.0   \n",
       "322            3.0                                          1.0   \n",
       "716            7.0                                          1.0   \n",
       "1096          11.0                                          2.0   \n",
       "\n",
       "      input_footprint_transportation_mpg1  \\\n",
       "588                                  22.0   \n",
       "983                                  22.0   \n",
       "638                                  22.0   \n",
       "266                                  22.0   \n",
       "1010                                 22.0   \n",
       "...                                   ...   \n",
       "1025                                 22.0   \n",
       "141                                  22.0   \n",
       "322                                  22.0   \n",
       "716                                  22.0   \n",
       "1096                                 22.0   \n",
       "\n",
       "      input_footprint_transportation_miles1  \\\n",
       "588                                 15600.0   \n",
       "983                                 12700.0   \n",
       "638                                  9400.0   \n",
       "266                                  5800.0   \n",
       "1010                                 8200.0   \n",
       "...                                     ...   \n",
       "1025                                 9100.0   \n",
       "141                                  3000.0   \n",
       "322                                  7000.0   \n",
       "716                                 18100.0   \n",
       "1096                                16100.0   \n",
       "\n",
       "      input_footprint_transportation_fuel1  airflights  \\\n",
       "588                                    1.0         2.0   \n",
       "983                                    1.0         6.0   \n",
       "638                                    1.0         7.0   \n",
       "266                                    1.0         4.0   \n",
       "1010                                   1.0         6.0   \n",
       "...                                    ...         ...   \n",
       "1025                                   1.0        11.0   \n",
       "141                                    1.0         4.0   \n",
       "322                                    1.0         1.0   \n",
       "716                                    1.0         9.0   \n",
       "1096                                   1.0         6.0   \n",
       "\n",
       "      input_footprint_housing_electricity_dollars  \\\n",
       "588                                         480.0   \n",
       "983                                         480.0   \n",
       "638                                         670.0   \n",
       "266                                         370.0   \n",
       "1010                                        540.0   \n",
       "...                                           ...   \n",
       "1025                                       1070.0   \n",
       "141                                         250.0   \n",
       "322                                         520.0   \n",
       "716                                         690.0   \n",
       "1096                                        820.0   \n",
       "\n",
       "      input_footprint_housing_squarefeet  \\\n",
       "588                               1590.5   \n",
       "983                               1993.0   \n",
       "638                               1689.0   \n",
       "266                               1419.0   \n",
       "1010                              2217.0   \n",
       "...                                  ...   \n",
       "1025                              2217.0   \n",
       "141                               1420.0   \n",
       "322                               1419.0   \n",
       "716                               1750.0   \n",
       "1096                              2500.0   \n",
       "\n",
       "      input_footprint_shopping_goods_clothing  result_grand_total  \n",
       "588                                136.451019           23.324704  \n",
       "983                                251.748512           37.518058  \n",
       "638                                198.743174           29.656163  \n",
       "266                                 81.291788           17.516040  \n",
       "1010                               307.046647           37.328012  \n",
       "...                                       ...                 ...  \n",
       "1025                               349.025009           45.620547  \n",
       "141                                 92.352685           12.257499  \n",
       "322                                 76.754155           17.213900  \n",
       "716                                293.132048           36.638812  \n",
       "1096                               438.915916           55.037524  \n",
       "\n",
       "[934 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 925543da5d490ccd4c20cf6f298124ea0dacefd7
   "source": [
    "df1 = pd.read_csv('../../data/new-cleaned-household-data.csv')\n",
    "df1['airflights'] = df1['input_footprint_transportation_airshort']+df1['input_footprint_transportation_airmedium']+df1['input_footprint_transportation_airlong']\n",
    "df = df1[['input_income', 'input_footprint_transportation_num_vehicles', 'input_footprint_transportation_mpg1', 'input_footprint_transportation_miles1', 'input_footprint_transportation_fuel1', 'airflights', 'input_footprint_housing_electricity_dollars', 'input_footprint_housing_squarefeet', 'input_footprint_shopping_goods_clothing', 'result_grand_total']]\n",
    "\n",
    "df.reset_index(drop = False, inplace = True)\n",
    "\n",
    "train_data = df.sample(frac=train_size)\n",
    "test_data = df[df['index'].apply(lambda x: x not in train_data['index'].values)]\n",
    "\n",
    "train_data.drop(columns='index', inplace=True)\n",
    "test_data.drop(columns='index', inplace=True)\n",
<<<<<<< Updated upstream
    "train_data.shape, test_data.shape\n",
    "train_data"
=======
    "train_data.shape, test_data.shape"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting and Prediction Modeling (25 points)\n",
    "\n",
    "This section is where the rubber meets the road.  In it you must:\n",
    "1. Explore at least 3 prediction modeling approaches for each prediction question, ranging from the simple (e.g. linear regression, KNN) to the complex (e.g. SVM, random forests, Lasso).  \n",
    "2. Motivate all your modeling decisions.  This includes parameter choices (e.g., how many folds in k-fold cross validation, what time window you use for averaging your data) as well as model form (e.g., If you use regression trees, why?  If you include nonlinear features in a regression model, why?). \n",
    "1. Carefully describe your cross validation and model selection process.  You should partition your data into training and testing data sets.  The training data set is what you use for cross-validation (i.e. you sample from within it to create folds, etc.).  The testing data set is held to the very end of your efforts, and used to compare qualitatively different models (e.g. OLS vs random forests).\n",
    "4. Very carefully document your workflow.  We will be reading a lot of projects, so we need you to explain each basic step in your analysis.  \n",
    "5. Seek opportunities to write functions allow you to avoid doing things over and over, and that make your code more succinct and readable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by looking at a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> 925543da5d490ccd4c20cf6f298124ea0dacefd7
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
<<<<<<< Updated upstream
<<<<<<< HEAD
=======
>>>>>>> Stashed changes
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-15cc5da02fd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'result_grand_total'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlin_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiagnostics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
<<<<<<< Updated upstream
      "\u001b[1;32m~\\Desktop\\carbon-footprint\\code\\model\\general_model_pipeline_vl.ipynb\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(data, y_col, test_size, random_state, standardize_cols)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;34m\"import matplotlib.pyplot as plt\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;34m\"import re\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;34m\"from sklearn.model_selection import train_test_split\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m\"from sklearn.metrics import mean_squared_error\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
=======
     "ename": "NameError",
     "evalue": "name 'gmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-15cc5da02fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_grand_total'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlin_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnostics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gmp' is not defined"
>>>>>>> 925543da5d490ccd4c20cf6f298124ea0dacefd7
=======
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\carbon-footprint\\code\\model\\general_model_pipeline_vl.ipynb\u001b[0m in \u001b[0;36mpreprocess_data\u001b[1;34m(data, y_col, test_size, random_state, standardize_cols)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;34m\"    \\\"\\\"\\\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;34m\"    This function takes a dataset and splits it up into training and testing data, \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[1;34m\"    as well as features and response variable.\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;34m\"    \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;34m\"    Input: data,             a Pandas dataframe\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = gmp.preprocess_data(train_data, 'result_grand_total')\n",
    "\n",
    "lm = LinearRegression()\n",
    "lin_model = gmp.run_model(X_train, X_val, y_train, y_val, lm, diagnostics = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model gave a Test MSE of 5.1157 and R^2 value of 0.9557, so this is a very good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move on to ridge regression. Since the linear model had a very good MSE and R^2 value, we do not expect ridge to do much better. In order to do this, we find the optimal value of alpha, a hyperparameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_val, y_val = gmp.preprocess_data(train_data, 'result_grand_total', standardize = True)\n",
    "\n",
    "alphas = [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gmp.linreg_kfold_cv(RidgeCV, X_train, X_val, y_train, y_val, alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave an optimal alpha value of 0.1. We will zoom in around that value to see if there is an even optimal valu of alpha and then see the new test MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_alphas = np.arange(0,1,0.01)\n",
    "gmp.linreg_kfold_cv(RidgeCV, X_train, X_val, y_train, y_val, new_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=0.66)\n",
    "ridge_model = gmp.run_model(X_train, X_val, y_train, y_val, ridge_model, diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ridge regressions showed slightly better results than that of linear regression with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_val, y_val = gmp.preprocess_data(train_data, 'result_grand_total',standardize = True)\n",
    "\n",
    "alphas = [0, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gmp.linreg_kfold_cv(LassoCV, X_train, X_val, y_train, y_val, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alphas_lasso = np.arange(0,0.001, 0.00005)\n",
    "gmp.linreg_kfold_cv(LassoCV, X_train, X_val, y_train, y_val, new_alphas_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = gmp.preprocess_data(train_data, 'result_grand_total', standardize = True)\n",
    "\n",
    "lasso_model = Lasso(alpha=0.00095)\n",
    "lasso_model = gmp.run_model(X_train, X_val, y_train, y_val, lasso_model, diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why i did decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = gmp.preprocess_data(train_data, 'result_grand_total')\n",
    "param_dist = {'max_leaf_nodes': np.arange(2, 20),\n",
    "              'max_features': np.arange(2, 10),\n",
    "              'max_depth': np.arange(2,10)}\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state = 100, max_depth = 4, max_features=5, max_leaf_nodes=10)\n",
    "gmp.tree_kfold_cv(tree, param_dist, X_train, y_train, n_iter=1000, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = gmp.preprocess_data(train_data, 'result_grand_total', standardize = False)\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=100, max_leaf_nodes = 19,\n",
    "                                   max_depth=5, max_features = 6)\n",
    "tree_model = gmp.run_model(X_train, X_val, y_train, y_val, tree_model, diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree is the worst model when compared to the linear, ridge, and lasso regression with the highest test MSE and R^2 value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Conclusions (20 points)\n",
    "In this section you must relate your modeling and forecasting results to your original prediction question.  You must:\n",
    "1. Address a resource allocation question.  What do the answers mean? What advice would you give a decision maker on the basis of your results?  How might they allocate their resources differently with the results of your model?  Why should the reader care about your results?\n",
    "2. Discuss caveats and / or reasons your results might be flawed.  No model is perfect, and understanding a model's imperfections is extremely important for the purpose of knowing how to interpret your results.  Often, we know the model output is wrong but we can assign a direction for its bias.  This helps to understand whether or not your answers are conservative.  \n",
    "\n",
    "Shoot for 500-1000 words for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of these models was to make the simpliest model based on the Cool Climate API data by using less and less features than the original data had whilc still "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
